# Note technique ‚Äì G√©n√©ralisation de l‚Äôapproche MLOps

## üéØ Objectif

Ce document pr√©sente une √©tude de cas bas√©e sur un projet r√©el de classification multilabel de questions Stack Overflow. Il vise √† explorer les approches et outils permettant de g√©n√©raliser une approche MLOps : automatisation du pipeline, tra√ßabilit√© des exp√©riences, et suivi des performances du mod√®le en production.

---

## üß© 1. Contexte du projet

- **Projet** : Classification automatique des questions Stack Overflow √† partir de leur contenu textuel.
- **Objectif** : Pr√©dire les tags associ√©s √† chaque question.
- **D√©fis rencontr√©s** :
  - Classification multilabel avec forte d√©s√©quilibre des classes.
  - Plus de 1000 tags possibles.
  - Mod√®les lents √† entra√Æner sur des donn√©es volumineuses.
  - Besoin de stabilit√© et de suivi du mod√®le dans le temps.

---

## ‚öôÔ∏è 2. Pipeline MLOps propos√©

### √âtapes clefs :

1. **Collecte & Pr√©traitement**
   - Donn√©es via l‚ÄôAPI Stack Exchange
   - Nettoyage du texte, vectorisation (TF-IDF ou embeddings)
   - Filtrage des tags (seulement ceux qui couvrent 90% des occurrences totales)
   - Encodage multilabel via `MultiLabelBinarizer`

2. **Mod√©lisation**
   - Algorithmes test√©s : `LogisticRegression`, `RandomForest`, `LinearSVC`, etc.
   - Recherche d‚Äôhyperparam√®tres via `RandomizedSearchCV`
   - Scores utilis√©s : `f1_micro`, `hamming_loss`, `subset_accuracy`

3. **D√©ploiement local (prototype)**
   - API simple via Flask ou FastAPI
   - Mod√®le sauvegard√© dans `models/supervised/`
   - Chargement du mod√®le + vectorizer pour la pr√©diction

4. **Monitoring & Suivi**
   - Suivi manuel mensuel sur 12 mois simul√©s
   - Calcul et visualisation des performances par mois
   - Pr√©paration √† l‚Äôint√©gration d‚Äôoutils comme `EvidentlyAI`

---

## üõ† 3. Outils recommand√©s

| √âtape                  | Outils recommand√©s                                     |
|------------------------|--------------------------------------------------------|
| Collecte               | Stack Exchange API, `pandas`, `json`                  |
| Preprocessing          | `scikit-learn`, `nltk`, `spacy`, `mlb`                |
| Mod√©lisation           | `scikit-learn`, `xgboost`, `lightgbm`, `Optuna`       |
| Tracking des exp√©riences | `MLflow`, `Weights & Biases`, `Neptune.ai`           |
| D√©ploiement            | `Flask`, `FastAPI`, `Docker`, `DVC`, `GitHub Actions` |
| Monitoring             | `EvidentlyAI`, `Prometheus`, `Grafana`                |
| CI/CD                  | `Git`, `GitHub Actions`, `DVC pipelines`              |

---

## üìä 4. √âtude de cas : suivi de performance temporelle

En attendant l‚Äôint√©gration compl√®te d‚Äôun outil de monitoring, nous avons simul√© le suivi de la performance sur 12 mois :

```python
df['CreationDate'] = pd.to_datetime(df['CreationDate'])
df['month'] = df['CreationDate'].dt.to_period('M')

monthly_data = {
    str(month): df_month
    for month, df_month in df.groupby('month')
}

for month, df_month in monthly_data.items():
    X_month = vectorizer.transform(df_month['text'])
    y_true = mlb.transform(df_month['tags'])
    y_pred = model.predict(X_month)
    
    print(f"---- {month} ----")
    print("F1 score:", f1_score(y_true, y_pred, average='micro'))
    # Ajouter √©ventuellement plus de m√©triques
```

Cette analyse permet de :
- Suivre l‚Äô√©volution de la qualit√© du mod√®le
- D√©tecter des d√©rives potentielles (data drift, concept drift)
- Identifier les mois o√π certains tags deviennent moins pr√©dictibles

---

## üß† 5. Proposition de g√©n√©ralisation MLOps

### Id√©e : Structurer un pipeline r√©utilisable avec :

- Un dossier `/pipeline/` contenant tous les scripts (ingestion, nettoyage, entra√Ænement)
- Des param√®tres centralis√©s dans un fichier `config.yaml`
- Suivi automatique avec `MLflow`
- D√©ploiement continu avec `GitHub Actions`
- Monitoring automatique avec `EvidentlyAI`

---

## ‚úÖ 6. B√©n√©fices attendus

- **Reproductibilit√©** des r√©sultats
- **Fiabilit√©** du mod√®le en production
- **R√©duction de la dette technique**
- **Suivi en temps r√©el** des d√©rives
- **Collaboration facilit√©e** entre data scientists et d√©veloppeurs

---

## üìå Conclusion

Cette √©tude montre qu‚Äôil est possible de structurer une d√©marche MLOps √† partir d‚Äôun projet r√©el, en mettant en ≈ìuvre des outils simples mais puissants comme `MLflow`, `EvidentlyAI`, `scikit-learn`, `FastAPI` et `GitHub Actions`. Ce pipeline peut ensuite √™tre adapt√© et √©tendu √† d‚Äôautres projets similaires.